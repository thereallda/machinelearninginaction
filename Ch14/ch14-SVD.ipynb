{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a403a0e",
   "metadata": {},
   "source": [
    "# Chapter 14 SVD\n",
    "\n",
    "奇异值分解（Singular Value Decomposition, SVD）是一种从数据中提取主要信息的方法。\n",
    "\n",
    "SVD能够从有噪声的数据中抽取相关特征。\n",
    "\n",
    "SVD将原始数据矩阵分为三个部分：\n",
    "\n",
    "${Data_{mxn} = U_{mxm}\\sum_{mxn}V^T{nxn}}$\n",
    "\n",
    "其中矩阵 ${\\sum_{mxn}}$ \n",
    "- 只包含对角元素，而其他元素为0\n",
    "- 对角元素从大到小排序\n",
    "- 这些对角元素被称为奇异值（Singular Value）\n",
    "- 奇异值是矩阵 ${Data * Data^T}$ 特征值的平方根\n",
    "\n",
    "![](img/img1.png)\n",
    "\n",
    "通过奇异值可以判断特征的重要性。例如，对某些数据进行SVD会发现在r个奇异值后，其余的奇异值均为0.这些0值的奇异值就是噪声或冗余特征。\n",
    "\n",
    "## SVD工作流程\n",
    "\n",
    "1. 准备数据（数据清洗）\n",
    "2. 矩阵分解\n",
    "3. 计算矩阵的能量信息\n",
    "4. 重构矩阵\n",
    "\n",
    "Numpy中的一个函数 `linalg.svd()` 可以实现矩阵的SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51dfbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import numpy as np\n",
    "# input: array\n",
    "U,Sigma,VT = linalg.svd([[1,1], [7,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffaae234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14142136, -0.98994949],\n",
       "       [-0.98994949,  0.14142136]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output: array\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb93b28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d442862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.70710678],\n",
       "       [-0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8ac7f",
   "metadata": {},
   "source": [
    "其中 `Sigma` 只包括了对角元素，而省略了0元素。\n",
    "\n",
    "创建如下矩阵：\n",
    "\n",
    "```python\n",
    "def loadExData():\n",
    "    return[[0, 0, 0, 2, 2],\n",
    "           [0, 0, 0, 3, 3],\n",
    "           [0, 0, 0, 1, 1],\n",
    "           [1, 1, 1, 0, 0],\n",
    "           [2, 2, 2, 0, 0],\n",
    "           [5, 5, 5, 0, 0],\n",
    "           [1, 1, 1, 0, 0]]\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f9d7824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.64365076e+00, 5.29150262e+00, 7.40623935e-16, 4.05103551e-16,\n",
       "       2.21838243e-32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import svdRec\n",
    "Data = svdRec.loadExData()\n",
    "U,Sigma,VT = linalg.svd(Data)\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2991649",
   "metadata": {},
   "source": [
    "计算奇异值后，一种判断奇异值保留数目的方法是通过奇异值的平方和计算矩阵的能量信息。一般认为保留90%的能量信息就足够了。所以，可以通过计算矩阵能量信息来判断要保留的奇异值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48ef2dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76859504, 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumsum(Sigma**2)/sum(Sigma**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0fee3",
   "metadata": {},
   "source": [
    "前两个奇异值相加的能量信息已经到达1（可能是由于计算误差，显示不了足够的小数）。所以，保留前两个奇异值就足够了。\n",
    "接下来，根据前两个奇异值，我们可以重构矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f8fcea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 5.38896529e-16,  1.58498979e-15,  1.58498979e-15,\n",
       "          2.00000000e+00,  2.00000000e+00],\n",
       "        [-1.04609326e-15,  5.23046632e-16,  5.23046632e-16,\n",
       "          3.00000000e+00,  3.00000000e+00],\n",
       "        [-3.48697754e-16,  1.74348877e-16,  1.74348877e-16,\n",
       "          1.00000000e+00,  1.00000000e+00],\n",
       "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00],\n",
       "        [ 2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00],\n",
       "        [ 5.00000000e+00,  5.00000000e+00,  5.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00],\n",
       "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sig2 = mat([[Sigma[0], 0], [0, Sigma[1]]])\n",
    "U[:,:2]*Sig2*VT[:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99cbf4",
   "metadata": {},
   "source": [
    "# 相似度计算\n",
    "\n",
    "1. 基于距离：${相似度 = 1/（1+距离）}$；距离为0时，相似度为1，距离很大时，相似度很小\n",
    "2. Pearson's correlation：${0.5 + 0.5*cor}$\n",
    "3. Cosine similarity: ${cos\\theta = \\frac{A\\dot B}{||A||\\dot||B||}}$ ; 两个向量方向相同，相似度为1，两个向量夹角为90度时，相似度为0\n",
    "\n",
    "其中 ${||A||, ||B||}$ 为向量A和B的2范数，例如向量 ${[4,2,2]}$ 的2范数：${\\sqrt{4^2 + 2^2 + 2^2})}$\n",
    "\n",
    "三者的python实现：\n",
    "\n",
    "```python\n",
    "def ecludSim(inA,inB):\n",
    "    return 1.0/(1.0 + la.norm(inA - inB))\n",
    "\n",
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 : return 1.0\n",
    "    return 0.5+0.5*corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T*inB)\n",
    "    denom = la.norm(inA)*la.norm(inB)\n",
    "    return 0.5+0.5*(num/denom)\n",
    "```\n",
    "\n",
    "\n",
    "# 小结\n",
    "\n",
    "SVD是一种降维工具，我们可以利用SVD来逼近矩阵并从中提取重要特征。通过保留矩阵的80%~90%的能量，我们就可以提取重要的特征并去除噪声。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
